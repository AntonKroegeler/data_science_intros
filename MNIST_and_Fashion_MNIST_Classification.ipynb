{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST and Fashion MNIST Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasperLS/data_science_intros/blob/main/MNIST_and_Fashion_MNIST_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNQ1UckPS99F"
      },
      "source": [
        "# MNIST & Fashion MNIST Classification Notebook\n",
        "This notebook is losely based on the example provided at https://victorzhou.com/blog/keras-neural-network-tutorial/: \n",
        "\n",
        "MNIST is publicly available image data set which consists of 28 by 28 pixels image of hand-written single digits. So each image in MNIST is an image of a digit from 0 to 9. MNIST challenge is to develop a machine learning algorithm that can classify these images into 10 classes (0 to 9).\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z78pX8IjiBjr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl2oW1o-gPl6"
      },
      "source": [
        "!pip install mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fPVR2wjhLqr"
      },
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfCrGCJ5nV1"
      },
      "source": [
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHi8wQoF0NND"
      },
      "source": [
        "# load alternative fashion mnist dataset\n",
        "# import tensorflow as tf\n",
        "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ES1Axj7iMsH"
      },
      "source": [
        "## Understand the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUUl3gDJi-Kx"
      },
      "source": [
        "# how many examples do we have?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaQsOC7BiUPy"
      },
      "source": [
        "# what resolution do our images have?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRpVt-FizYx"
      },
      "source": [
        "# let's look at some examples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKQgmVQjoEg"
      },
      "source": [
        "# how many do we have of each example?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_77Auz8jnGbf"
      },
      "source": [
        "# how is our image data represented?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGvVYkgQiRYo"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyFEyFpxjjGF"
      },
      "source": [
        "# normalize the images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqyb_D83u0SE"
      },
      "source": [
        "# flatten the images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txBchLoguyLj"
      },
      "source": [
        "# do we need to transform labels (later)?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffrUd_DGqqqX"
      },
      "source": [
        "## Get the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzU0XPuqrH_D"
      },
      "source": [
        "# build the model\n",
        "model = Sequential([\n",
        "  Dense(64, activation='relu', input_shape=(784,)),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy', \n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1YRM6bPoMhS"
      },
      "source": [
        "# what will be our number of parameters for the first layer? -Let's figure it out!\n",
        "\n",
        "# let's take a look at our model?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H8GjzSYuoQR"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXoZkZ2evqkY"
      },
      "source": [
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=2,\n",
        "  batch_size=32\n",
        "  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jDf1xVlxLUL"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03roFy8jgfUm"
      },
      "source": [
        "model.evaluate( \n",
        "  test_images, \n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "# predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# print our model's predictions\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# check our predictions against the ground truths\n",
        "print(test_labels[:5]) \n",
        "\n",
        "# Wouldn't it be nice to track testing loss while training?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0v3QSH_dJHE"
      },
      "source": [
        "## Save (and Load) Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eM3O0gydN--"
      },
      "source": [
        "# how do we save a model?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnqYTkafBtv"
      },
      "source": [
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXw02EtNfw8v"
      },
      "source": [
        "reconstructed_model.evaluate( \n",
        "  test_images, \n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "# predict on the first 5 test images.\n",
        "predictions = reconstructed_model.predict(test_images[:5])\n",
        "\n",
        "# print our model's predictions\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# check our predictions against the ground truths\n",
        "print(test_labels[:5]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6UFLtw9f1dx"
      },
      "source": [
        "reconstructed_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucWGgYkd1Lw3"
      },
      "source": [
        "## Try Alternative Model incl. CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-0jtJuBnNI"
      },
      "source": [
        "##### Get Model inlc. CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHfeE1z3VRV"
      },
      "source": [
        "model = Sequential([\n",
        "  # add convolution layer here\n",
        "  # do we add more here?\n",
        "  # transform data here\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy', \n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# let's take a look at our model\n",
        "model.summary()\n",
        "\n",
        "# why do we get the specific number of parameters?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zrOxQU6BsOw"
      },
      "source": [
        "##### Train CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPoBdXtR8gFC"
      },
      "source": [
        "model.fit(\n",
        "  train_images, # how to get the correct shape?\n",
        "  to_categorical(train_labels),\n",
        "  epochs=5,\n",
        "  batch_size=64,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),# again\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX8qk0RABu8e"
      },
      "source": [
        "##### Evaluate CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbtT_mdWBlO_"
      },
      "source": [
        "model.evaluate( \n",
        "  test_images, \n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "# predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# print our model's predictions\n",
        "print(np.argmax(predictions, axis=1)) \n",
        "\n",
        "# check our predictions against the ground truths\n",
        "print(test_labels[:5]) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}